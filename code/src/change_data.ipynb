{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dlf/miniconda3/envs/prompt/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline,BertForMaskedLM\n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForMaskedLM\n",
    "from transformers import AutoModelForMaskedLM\n",
    "from transformers import TrainingArguments\n",
    "from data_processing import  get_all_data\n",
    "from transformers import Trainer\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import default_data_collator\n",
    "from torch.optim import AdamW\n",
    "# from accelerate import Accelerator\n",
    "from transformers import get_scheduler\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import math\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset,DatasetDict,Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def group_texts(examples):\n",
    "    # Concatenate all texts\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    # Compute length of concatenated texts\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the last chunk if it's smaller than chunk_size\n",
    "    total_length = (total_length // chunk_size) * chunk_size\n",
    "    # Split by chunks of max_len\n",
    "    result = {\n",
    "        k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    # Create a new labels column\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/dlf/prompt/code/model/bert_large_chinese were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "    datas = ['在句子\"脉细弦\"中，词语\"脉\"的前文如果是由\"[CLS]\"词性的词语\"[CLS]\"来修饰，那么词语\"脉\"的词性是\"[MASK]\"→ NR', '在句子\"脉细弦\"中，词语\"细\"的前文如果是由\"NR\"词性的词语\"脉\"来修饰，那么词语\"细\"的词性是\"[MASK]\"→ VA', '在句子\"脉细弦\"中，词语\"弦\"的前文如果是由\"VA\"词性的词语\"细\"来修饰，那么词语\"弦\"的词性是\"[MASK]\"→ VA']\n",
    "\n",
    "\n",
    "    device = torch.device('cpu')\n",
    "    model_checkpoint =  \"/home/dlf/prompt/code/model/bert_large_chinese\"\n",
    "    # model_checkpoint = \"distilbert-base-uncased\"\n",
    "    model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "    batch_size = 32\n",
    "    train,valid,test = get_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def tokenize_function(examples):\n",
    "\n",
    "        # # result = tokenizer(examples[\"text\"].split(\"→\")[0])\n",
    "        datas = [item.split(\"→\")[0] for item in examples]\n",
    "\n",
    "        labels = [item.split(\"→\")[1].replace(\"\\n\", \"\") for item in examples]\n",
    "        result = tokenizer(labels, return_tensors=\"pt\",padding=\"max_length\",max_length=512)\n",
    "        # result = tokenizer(labels, return_tensors=\"pt\",padding=\"max_length\",max_length=512)\n",
    "        # label = tokenizer(labels,padding=True, truncation=True,return_tensors=\"pt\")\n",
    "\n",
    "        ids = tokenizer.convert_tokens_to_ids(labels)\n",
    "        # if tokenizer.is_fast:\n",
    "        #     result[\"word_ids\"] = [result.word_ids(i) for i in range(len(result[\"input_ids\"]))]\n",
    "        result[\"labels\"] = torch.tensor([ids])\n",
    "        \n",
    "        # torch.tensor([ids])\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset text (/home/dlf/.cache/huggingface/datasets/text/default-06f2ffa854942ad7/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2)\n",
      "100%|██████████| 1/1 [00:00<00:00, 308.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    }
   ],
   "source": [
    "    dataset = load_dataset(\"text\",data_files=\"/home/dlf/prompt/code/src/dataset.txt\")\n",
    "    temp = tokenize_function(train)\n",
    "    train = temp\n",
    "    print(type(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Show the training loss with every epoch\n",
    "    logging_steps = len(train) // batch_size\n",
    "    model_name = model_checkpoint.split(\"/\")[-1]\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"{model_name}-finetuned-imdb\",\n",
    "        overwrite_output_dir=True,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        weight_decay=0.01,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        push_to_hub=False,\n",
    "        fp16=False,\n",
    "        logging_steps=1,\n",
    "    )\n",
    "\n",
    "    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.0)\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train,\n",
    "        eval_dataset=train,\n",
    "        data_collator=data_collator,\n",
    "    )\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "    train_dataloader = DataLoader(\n",
    "        train,\n",
    "        shuffle=True,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=data_collator,\n",
    "    )\n",
    "    eval_dataloader = DataLoader(\n",
    "        train,\n",
    "        shuffle=True,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=data_collator,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "num_train_epochs = 3\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tokenizers.Encoding' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_train_epochs):\n\u001b[1;32m      4\u001b[0m     \u001b[39m# Training\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m----> 6\u001b[0m     \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_dataloader:\n\u001b[1;32m      7\u001b[0m         \u001b[39m# batch = torch.tensor(batch, dtype=torch.long, device=device)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m         data \u001b[39m=\u001b[39m batch\n\u001b[1;32m      9\u001b[0m         outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdata)\n",
      "File \u001b[0;32m~/miniconda3/envs/prompt/lib/python3.8/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/prompt/lib/python3.8/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/prompt/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:61\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 61\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/prompt/lib/python3.8/site-packages/transformers/data/data_collator.py:45\u001b[0m, in \u001b[0;36mDataCollatorMixin.__call__\u001b[0;34m(self, features, return_tensors)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtf_call(features)\n\u001b[1;32m     44\u001b[0m \u001b[39melif\u001b[39;00m return_tensors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 45\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtorch_call(features)\n\u001b[1;32m     46\u001b[0m \u001b[39melif\u001b[39;00m return_tensors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnp\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     47\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumpy_call(features)\n",
      "File \u001b[0;32m~/miniconda3/envs/prompt/lib/python3.8/site-packages/transformers/data/data_collator.py:726\u001b[0m, in \u001b[0;36mDataCollatorForLanguageModeling.torch_call\u001b[0;34m(self, examples)\u001b[0m\n\u001b[1;32m    723\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39mpad(examples, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m, pad_to_multiple_of\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpad_to_multiple_of)\n\u001b[1;32m    724\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    725\u001b[0m     batch \u001b[39m=\u001b[39m {\n\u001b[0;32m--> 726\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m: _torch_collate_batch(examples, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenizer, pad_to_multiple_of\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpad_to_multiple_of)\n\u001b[1;32m    727\u001b[0m     }\n\u001b[1;32m    729\u001b[0m \u001b[39m# If special token mask has been preprocessed, pop it from the dict.\u001b[39;00m\n\u001b[1;32m    730\u001b[0m special_tokens_mask \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mspecial_tokens_mask\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/prompt/lib/python3.8/site-packages/transformers/data/data_collator.py:403\u001b[0m, in \u001b[0;36m_torch_collate_batch\u001b[0;34m(examples, tokenizer, pad_to_multiple_of)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(examples[\u001b[39m0\u001b[39m], (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m, np\u001b[39m.\u001b[39mndarray)):\n\u001b[1;32m    401\u001b[0m     examples \u001b[39m=\u001b[39m [torch\u001b[39m.\u001b[39mtensor(e, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong) \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m examples]\n\u001b[0;32m--> 403\u001b[0m length_of_first \u001b[39m=\u001b[39m examples[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49msize(\u001b[39m0\u001b[39m)\n\u001b[1;32m    405\u001b[0m \u001b[39m# Check if padding is necessary.\u001b[39;00m\n\u001b[1;32m    407\u001b[0m are_tensors_same_length \u001b[39m=\u001b[39m \u001b[39mall\u001b[39m(x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m) \u001b[39m==\u001b[39m length_of_first \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m examples)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tokenizers.Encoding' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        # batch = torch.tensor(batch, dtype=torch.long, device=device)\n",
    "        data = batch\n",
    "        outputs = model(**data)\n",
    "        loss = outputs.loss\n",
    "        # accelerator.backward(loss)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        with torch.no_grad():\n",
    "            data = batch\n",
    "            outputs = model(data)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        # losses.append(accelerator.gather(loss.repeat(batch_size)))\n",
    "        losses.append(loss)\n",
    "\n",
    "    losses = torch.cat(losses)\n",
    "    losses = losses[: len(eval_dataset)]\n",
    "    try:\n",
    "        perplexity = math.exp(torch.mean(losses))\n",
    "    except OverflowError:\n",
    "        perplexity = float(\"inf\")\n",
    "\n",
    "    print(f\">>> Epoch {epoch}: Perplexity: {perplexity}\")\n",
    "\n",
    "    # Save and upload\n",
    "    # accelerator.wait_for_everyone()\n",
    "    # unwrapped_model = accelerator.unwrap_model(model)\n",
    "    # unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
    "    # if accelerator.is_main_process:\n",
    "    #     tokenizer.save_pretrained(output_dir)\n",
    "    #     repo.push_to_hub(\n",
    "    #         commit_message=f\"Training in progress epoch {epoch}\", blocking=False\n",
    "    #     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
